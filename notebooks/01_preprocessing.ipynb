{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99403db-79a8-42d3-9a84-6a9642fbe594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 2500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>6982</td>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒIm...</td>\n",
       "      <td>2025-06-18 06:01:10+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>6981</td>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ B...</td>\n",
       "      <td>2025-06-16 12:21:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>6980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-16 05:11:57+00:00</td>\n",
       "      <td>photos\\@ZemenExpress_6980.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>6979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-16 05:11:57+00:00</td>\n",
       "      <td>photos\\@ZemenExpress_6979.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>6978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-16 05:11:57+00:00</td>\n",
       "      <td>photos\\@ZemenExpress_6978.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Channel Title Channel Username    ID  \\\n",
       "0  Zemen ExpressÂ®    @ZemenExpress  6982   \n",
       "1  Zemen ExpressÂ®    @ZemenExpress  6981   \n",
       "2  Zemen ExpressÂ®    @ZemenExpress  6980   \n",
       "3  Zemen ExpressÂ®    @ZemenExpress  6979   \n",
       "4  Zemen ExpressÂ®    @ZemenExpress  6978   \n",
       "\n",
       "                                             Message  \\\n",
       "0  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒIm...   \n",
       "1  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ B...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        Date                     Media Path  \n",
       "0  2025-06-18 06:01:10+00:00                            NaN  \n",
       "1  2025-06-16 12:21:00+00:00                            NaN  \n",
       "2  2025-06-16 05:11:57+00:00  photos\\@ZemenExpress_6980.jpg  \n",
       "3  2025-06-16 05:11:57+00:00  photos\\@ZemenExpress_6979.jpg  \n",
       "4  2025-06-16 05:11:57+00:00  photos\\@ZemenExpress_6978.jpg  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the scraped Telegram data\n",
    "df = pd.read_csv(\"../telegram_data.csv\",encoding='utf-8')\n",
    "\n",
    "# Show structure\n",
    "print(\"Total rows:\", len(df))\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79f2d7b-ec7c-4eaa-ab6d-6233551ec213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Cleaned_Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒIm...</td>\n",
       "      <td>Imitation Volcano Humidifier with LED Light á‰ áŠ¤...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ B...</td>\n",
       "      <td>Baby Carrier á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒSm...</td>\n",
       "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒBa...</td>\n",
       "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ğŸ’¥ğŸ’¥...............ğŸŒ.................ğŸ’¥ğŸ’¥\\n\\nâ“ á‰ áˆ¨á...</td>\n",
       "      <td>á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Message  \\\n",
       "0   ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒIm...   \n",
       "1   ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ B...   \n",
       "9   ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒSm...   \n",
       "12  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒBa...   \n",
       "14  ğŸ’¥ğŸ’¥...............ğŸŒ.................ğŸ’¥ğŸ’¥\\n\\nâ“ á‰ áˆ¨á...   \n",
       "\n",
       "                                      Cleaned_Message  \n",
       "0   Imitation Volcano Humidifier with LED Light á‰ áŠ¤...  \n",
       "1   Baby Carrier á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ ...  \n",
       "9   Smart Usb Ultrasonic Car And Home Air Humidifi...  \n",
       "12  Baby Head Helmet Cotton Walk Safety Hat Breath...  \n",
       "14  á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Drop rows with empty messages\n",
    "df = df.dropna(subset=['Message'])\n",
    "\n",
    "# Remove duplicates (based on message text)\n",
    "df = df.drop_duplicates(subset=['Message'])\n",
    "\n",
    "# Function to clean Amharic messages\n",
    "def clean_message(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Remove emojis and special characters (optional)\n",
    "    text = re.sub(r'[^\\w\\sá¡á¢á£á¤á¥á¦á§á¨á‰¥áˆ­áˆ˜á‹áŠ“á‰¥á‹‹á‰µáŠ“áŠ•]', '', text)\n",
    "    \n",
    "    # Normalize multiple spaces/newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Apply cleaning function\n",
    "df['Cleaned_Message'] = df['Message'].apply(clean_message)\n",
    "\n",
    "# Show sample\n",
    "df[['Message', 'Cleaned_Message']].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d51c18b-eda6-4fd7-84c5-ed64b8fd7577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Message</th>\n",
       "      <th>Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imitation Volcano Humidifier with LED Light á‰ áŠ¤...</td>\n",
       "      <td>[Imitation, Volcano, Humidifier, with, LED, Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baby Carrier á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ ...</td>\n",
       "      <td>[Baby, Carrier, á‰ áˆáˆˆáŒ‰á‰µ, áŠ á‰…áŒ£áŒ«, áˆáŒ…á‹áŠ•, á‰ áˆá‰¾á‰µ, áˆ›á‹˜áˆ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
       "      <td>[Smart, Usb, Ultrasonic, Car, And, Home, Air, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
       "      <td>[Baby, Head, Helmet, Cotton, Walk, Safety, Hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...</td>\n",
       "      <td>[á‰ áˆ¨áá‰µ, á‰€áŠ•á‹, áˆ±á‰…, áˆ‹á‹­, áˆ˜áˆµá‰°áŠ“áŒˆá‹µ, áˆˆáˆá‰µáˆáˆáŒ‰, á‹á‹µ, á‹°áŠ•á‰ áŠá‰»á‰½...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Cleaned_Message  \\\n",
       "0   Imitation Volcano Humidifier with LED Light á‰ áŠ¤...   \n",
       "1   Baby Carrier á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ ...   \n",
       "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
       "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
       "14  á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...   \n",
       "\n",
       "                                               Tokens  \n",
       "0   [Imitation, Volcano, Humidifier, with, LED, Li...  \n",
       "1   [Baby, Carrier, á‰ áˆáˆˆáŒ‰á‰µ, áŠ á‰…áŒ£áŒ«, áˆáŒ…á‹áŠ•, á‰ áˆá‰¾á‰µ, áˆ›á‹˜áˆ, ...  \n",
       "9   [Smart, Usb, Ultrasonic, Car, And, Home, Air, ...  \n",
       "12  [Baby, Head, Helmet, Cotton, Walk, Safety, Hat...  \n",
       "14  [á‰ áˆ¨áá‰µ, á‰€áŠ•á‹, áˆ±á‰…, áˆ‹á‹­, áˆ˜áˆµá‰°áŠ“áŒˆá‹µ, áˆˆáˆá‰µáˆáˆáŒ‰, á‹á‹µ, á‹°áŠ•á‰ áŠá‰»á‰½...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the cleaned Amharic message\n",
    "def tokenize_amharic(text):\n",
    "    # Basic whitespace tokenizer\n",
    "    return text.split()\n",
    "\n",
    "# Apply tokenization\n",
    "df['Tokens'] = df['Cleaned_Message'].apply(tokenize_amharic)\n",
    "\n",
    "# Preview tokens\n",
    "df[['Cleaned_Message', 'Tokens']].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbb1a8a-4935-45be-aace-705ade3bc376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>Date</th>\n",
       "      <th>Cleaned_Message</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>2025-06-18 06:01:10+00:00</td>\n",
       "      <td>Imitation Volcano Humidifier with LED Light á‰ áŠ¤...</td>\n",
       "      <td>[Imitation, Volcano, Humidifier, with, LED, Li...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>2025-06-16 12:21:00+00:00</td>\n",
       "      <td>Baby Carrier á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ ...</td>\n",
       "      <td>[Baby, Carrier, á‰ áˆáˆˆáŒ‰á‰µ, áŠ á‰…áŒ£áŒ«, áˆáŒ…á‹áŠ•, á‰ áˆá‰¾á‰µ, áˆ›á‹˜áˆ, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>2025-06-16 05:11:57+00:00</td>\n",
       "      <td>Smart Usb Ultrasonic Car And Home Air Humidifi...</td>\n",
       "      <td>[Smart, Usb, Ultrasonic, Car, And, Home, Air, ...</td>\n",
       "      <td>photos\\@ZemenExpress_6973.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>2025-06-16 05:09:03+00:00</td>\n",
       "      <td>Baby Head Helmet Cotton Walk Safety Hat Breath...</td>\n",
       "      <td>[Baby, Head, Helmet, Cotton, Walk, Safety, Hat...</td>\n",
       "      <td>photos\\@ZemenExpress_6970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zemen ExpressÂ®</td>\n",
       "      <td>@ZemenExpress</td>\n",
       "      <td>2025-06-14 14:40:03+00:00</td>\n",
       "      <td>á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...</td>\n",
       "      <td>[á‰ áˆ¨áá‰µ, á‰€áŠ•á‹, áˆ±á‰…, áˆ‹á‹­, áˆ˜áˆµá‰°áŠ“áŒˆá‹µ, áˆˆáˆá‰µáˆáˆáŒ‰, á‹á‹µ, á‹°áŠ•á‰ áŠá‰»á‰½...</td>\n",
       "      <td>photos\\@ZemenExpress_6968.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel Title Channel Username                       Date  \\\n",
       "0   Zemen ExpressÂ®    @ZemenExpress  2025-06-18 06:01:10+00:00   \n",
       "1   Zemen ExpressÂ®    @ZemenExpress  2025-06-16 12:21:00+00:00   \n",
       "9   Zemen ExpressÂ®    @ZemenExpress  2025-06-16 05:11:57+00:00   \n",
       "12  Zemen ExpressÂ®    @ZemenExpress  2025-06-16 05:09:03+00:00   \n",
       "14  Zemen ExpressÂ®    @ZemenExpress  2025-06-14 14:40:03+00:00   \n",
       "\n",
       "                                      Cleaned_Message  \\\n",
       "0   Imitation Volcano Humidifier with LED Light á‰ áŠ¤...   \n",
       "1   Baby Carrier á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ ...   \n",
       "9   Smart Usb Ultrasonic Car And Home Air Humidifi...   \n",
       "12  Baby Head Helmet Cotton Walk Safety Hat Breath...   \n",
       "14  á‰ áˆ¨áá‰µ á‰€áŠ•á‹ áˆ±á‰… áˆ‹á‹­ áˆ˜áˆµá‰°áŠ“áŒˆá‹µ áˆˆáˆá‰µáˆáˆáŒ‰ á‹á‹µ á‹°áŠ•á‰ áŠá‰»á‰½áŠ• áŠáŒˆ áŠ¨áŒ á‹‹...   \n",
       "\n",
       "                                               Tokens  \\\n",
       "0   [Imitation, Volcano, Humidifier, with, LED, Li...   \n",
       "1   [Baby, Carrier, á‰ áˆáˆˆáŒ‰á‰µ, áŠ á‰…áŒ£áŒ«, áˆáŒ…á‹áŠ•, á‰ áˆá‰¾á‰µ, áˆ›á‹˜áˆ, ...   \n",
       "9   [Smart, Usb, Ultrasonic, Car, And, Home, Air, ...   \n",
       "12  [Baby, Head, Helmet, Cotton, Walk, Safety, Hat...   \n",
       "14  [á‰ áˆ¨áá‰µ, á‰€áŠ•á‹, áˆ±á‰…, áˆ‹á‹­, áˆ˜áˆµá‰°áŠ“áŒˆá‹µ, áˆˆáˆá‰µáˆáˆáŒ‰, á‹á‹µ, á‹°áŠ•á‰ áŠá‰»á‰½...   \n",
       "\n",
       "                       Media Path  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "9   photos\\@ZemenExpress_6973.jpg  \n",
       "12  photos\\@ZemenExpress_6970.jpg  \n",
       "14  photos\\@ZemenExpress_6968.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select and reorder relevant columns\n",
    "structured_df = df[[\n",
    "    'Channel Title',\n",
    "    'Channel Username',\n",
    "    'Date',\n",
    "    'Cleaned_Message',\n",
    "    'Tokens',\n",
    "    'Media Path'\n",
    "]]\n",
    "\n",
    "# Preview structure\n",
    "structured_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dc08dd-06b1-4846-8aa1-5c34bc74c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create the clean data directory if it doesn't exist\n",
    "os.makedirs(\"../data/clean\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e46510c8-cfb6-455c-a13a-638d2c5ad374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to raw CoNLL-style file for manual tagging\n",
    "\n",
    "with open(\"../data/clean/unlabeled_conll.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for tokens in df['Tokens']:\n",
    "        for token in tokens:\n",
    "            f.write(f\"{token} O\\n\")  # Default tag: O\n",
    "        f.write(\"\\n\")  # Blank line between sentences/messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d6823ee-7adc-4173-ac4e-00a0c4aae7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Step 1a: Create folder (if missing)\n",
    "os.makedirs(\"../data/clean\", exist_ok=True)\n",
    "\n",
    "# Step 1b: Export tokens with default 'O' tags for manual labeling\n",
    "with open(\"../data/clean/unlabeled_conll.txt\", \"w\", encoding='utf-8') as f:\n",
    "    for tokens in df['Tokens']:\n",
    "        for token in tokens:\n",
    "            f.write(f\"{token} O\\n\")  # tag O = no entity\n",
    "        f.write(\"\\n\")  # blank line separates messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d558bfbd-5dec-4df9-9024-bc47a03e740f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Message  \\\n",
      "0  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“ŒIm...   \n",
      "1  ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\\n\\nğŸ“Œ B...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                     Cleaned_Message  \\\n",
      "0  Imitation Volcano Humidifier with LED Light á‰ áŠ¤...   \n",
      "1  Baby Carrier á‰ áˆáˆˆáŒ‰á‰µ áŠ á‰…áŒ£áŒ« áˆáŒ…á‹áŠ• á‰ áˆá‰¾á‰µ áˆ›á‹˜áˆ á‹«áˆµá‰½áˆá‹á‰³áˆ ...   \n",
      "2                                                      \n",
      "3                                                      \n",
      "4                                                      \n",
      "\n",
      "                                              Tokens  \n",
      "0  [Imitation, Volcano, Humidifier, with, LED, Li...  \n",
      "1  [Baby, Carrier, á‰ áˆáˆˆáŒ‰á‰µ, áŠ á‰…áŒ£áŒ«, áˆáŒ…á‹áŠ•, á‰ áˆá‰¾á‰µ, áˆ›á‹˜áˆ, ...  \n",
      "2                                                 []  \n",
      "3                                                 []  \n",
      "4                                                 []  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # Keep Amharic Unicode (\\u1200-\\u137F), Latin letters, numbers, and spaces only\n",
    "    text = re.sub(r'[^\\w\\s\\u1200-\\u137F]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)  # collapse multiple spaces\n",
    "    return text.strip()\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Apply cleaning and tokenizing\n",
    "df['Cleaned_Message'] = df['Message'].apply(clean_text)\n",
    "df['Tokens'] = df['Cleaned_Message'].apply(tokenize)\n",
    "\n",
    "# Check result\n",
    "print(df[['Message', 'Cleaned_Message', 'Tokens']].head())\n",
    "\n",
    "# Save the processed data for next steps\n",
    "df.to_csv('../data/clean/processed_telegram_data.csv', index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e355ede-d248-4424-a565-5f5bc2cc4deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
